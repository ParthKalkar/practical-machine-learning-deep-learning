{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA29Q964txoc"
      },
      "source": [
        "# Deep Learning best practices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy96QJvbtzZK"
      },
      "source": [
        "!pip install -q tensorflow==2.8.2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYhW66Ywtxoe"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, MaxPool2D, Lambda, Conv2D, Dense, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "57uEuxoN2Nxy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbpsmNQGtxow"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "num_classes = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fThZ8EWMtxoo"
      },
      "source": [
        "Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7bP0QTKtxoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6255a1ca-9b9a-40a6-cb27-434730184062"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
        "train_shape = x_train.shape\n",
        "test_shape = x_test.shape\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "#If you use a pretrained model, it might expect inputs to be in the [0-255] range, so you will need to comment this line\n",
        "# x_train, x_test = x_train / 255, x_test / 255 \n",
        "\n",
        "# ImageDataGenerator requires one hot encoding and 'categorical_crossentropy' loss \n",
        "y_train = np.eye(num_classes)[y_train.reshape(-1)]\n",
        "y_test = np.eye(num_classes)[y_test.reshape(-1)]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45gkErJYtxo0"
      },
      "source": [
        "Making the model: each layer with neurons numbers (units), activation, use_bias, ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "794SKDC2txo1"
      },
      "source": [
        "from tensorflow.keras.layers import Resizing, RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, RandomContrast\n",
        "\n",
        "# Task-1 *Parameters Tunning*\n",
        "#Tune number of units in each layer\n",
        "#Tune the activation (sigmoid, relu, tanh, linear, selu, .. visit: https://goo.gl/hdtK15\n",
        "def model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # https://keras.io/guides/preprocessing_layers/\n",
        "    # https://keras.io/api/layers/preprocessing_layers/image_augmentation/\n",
        "    model.add(Resizing(224, 224, input_shape=(32, 32, 3)))\n",
        "    model.add(RandomFlip(\"horizontal\"))\n",
        "    model.add(RandomTranslation(0.1, 0.1))\n",
        "    model.add(RandomRotation(0.1))\n",
        "    model.add(RandomZoom((-0.1, 0.1)))\n",
        "    model.add(RandomContrast(0.1))\n",
        "\n",
        "    pretrained = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "    pretrained.trainable = False\n",
        "    model.add(pretrained)\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D((5, 5)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    # model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "    model.add(Dense(units=128, use_bias=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units=64, use_bias=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(units=num_classes, use_bias=True, activation='softmax'))\n",
        "    #Try to tune the optimizer, visit: https://goo.gl/dHFJNy\n",
        "    #Try to tune the loss func, visit: https://goo.gl/xMrooU\n",
        "    #Try to tune learning rate (lr)\n",
        "    #In your free time take a look at different variations of GD: https://goo.gl/YFa6XY\n",
        "    sgd_optimizer = SGD(learning_rate=.01)\n",
        "    adam_optimizer = Adam(learning_rate=.01, clipnorm=1.)\n",
        "    model.compile(optimizer=adam_optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILbYn_bw77b1",
        "outputId": "d22d338c-c2fb-4038-c827-48358f6a0fbe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing_9 (Resizing)       (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_flip_8 (RandomFlip)  (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_translation_8 (Rando  (None, 224, 224, 3)      0         \n",
            " mTranslation)                                                   \n",
            "                                                                 \n",
            " random_rotation_8 (RandomRo  (None, 224, 224, 3)      0         \n",
            " tation)                                                         \n",
            "                                                                 \n",
            " random_zoom_7 (RandomZoom)  (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_contrast_7 (RandomCo  (None, 224, 224, 3)      0         \n",
            " ntrast)                                                         \n",
            "                                                                 \n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 5, 5, 256)         1179904   \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 5, 5, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,247,882\n",
            "Trainable params: 1,222,602\n",
            "Non-trainable params: 20,025,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69wHVyRwtxo4"
      },
      "source": [
        "Training and Evaluation on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKbqPEcvtxpC",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8db9b03-0eaf-4dee-b482-2cb96813475b"
      },
      "source": [
        "# Task-2 *Early Stopping*\n",
        "# Add Early stopping, to stop the training when the accuracy doesn't improve after 2 epochs\n",
        "# and restore the model weights which produced best training accuracy.\n",
        "\n",
        "# Task-3 *Validation Dataset generation*\n",
        "# - Have a validation set split of 20%.\n",
        "# - update the early stopping to stop on the validation accuracy.\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.3)\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          validation_split=0.2,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Loss:\", loss, \", Accuracy:\", acc)\n",
        "model.save_weights(filepath=\"my_model_weights.hdf5\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 297s 118ms/step - loss: 1.0898 - accuracy: 0.6227 - val_loss: 0.6154 - val_accuracy: 0.7947 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 324s 130ms/step - loss: 0.8845 - accuracy: 0.6988 - val_loss: 0.5310 - val_accuracy: 0.8179 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 292s 117ms/step - loss: 0.8176 - accuracy: 0.7189 - val_loss: 0.5103 - val_accuracy: 0.8292 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 324s 130ms/step - loss: 0.7723 - accuracy: 0.7377 - val_loss: 0.4782 - val_accuracy: 0.8373 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 292s 117ms/step - loss: 0.7522 - accuracy: 0.7443 - val_loss: 0.4636 - val_accuracy: 0.8413 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 324s 130ms/step - loss: 0.7250 - accuracy: 0.7530 - val_loss: 0.4628 - val_accuracy: 0.8427 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 293s 117ms/step - loss: 0.7075 - accuracy: 0.7613 - val_loss: 0.4454 - val_accuracy: 0.8470 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 324s 130ms/step - loss: 0.6967 - accuracy: 0.7621 - val_loss: 0.4515 - val_accuracy: 0.8444 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 326s 130ms/step - loss: 0.6740 - accuracy: 0.7702 - val_loss: 0.4256 - val_accuracy: 0.8524 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 325s 130ms/step - loss: 0.6603 - accuracy: 0.7746 - val_loss: 0.4410 - val_accuracy: 0.8467 - lr: 0.0100\n",
            "313/313 [==============================] - 56s 158ms/step - loss: 0.4585 - accuracy: 0.8402\n",
            "Loss: 0.4584525525569916 , Accuracy: 0.8402000069618225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "reJhreIAUe6D"
      },
      "source": [
        "## Tasks\n",
        "- Apply Dropout after the dense layers.\n",
        "- Apply BatchNormalization\n",
        "- Put Early Stopping.\n",
        "- Add a learning rate scheduler.\n",
        "- Add gradient clipping.\n",
        "- Use a pretrained model, e.g. VGG19 (optional).\n",
        "- Train with Augmentation (optional).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "- Why do we need gradient clipping?\n",
        "\n",
        "> If a model is very deep and has activations that are not limited from the upper side, like relu (in contrast with sigmoid or tanh). As you remember, the backpropagation starts from the end and goes forward layer by layer. That means the gradient is multiplied repeatedly on those positive numbers in each layer during backpropagation. These repeated multiplications may lead to gradient values becoming too large for stable training, that is called gradient explosion.\n",
        ">\n",
        "> A similar but opposite problem is when the weight are around zero -- the gradient can become too low for further layers to train, that is called gradient vanishing (residual connection is another solution to this problem). \n",
        ">\n",
        "> Gradient clipping, which is limiting its norm or components by value, is a solution to both described problems.\n",
        "\n",
        "- What are your steps if you are out of memory?\n",
        "\n",
        "> If you are out of GPU memory, you could, firstly, try **decreasing the batch size**, however, you should not make it too small, as it will affect training. Secondly, you can **decrease your model dimensions**, if you don't have to stick to the given specs. Apart from these general points, there are some advanced techniques: **gradient accumulation** or **automatic mixed precision**. And of course, you can buy or reserve more GPU memory.\n",
        "\n",
        "- How to select an optimal learning rate?\n",
        "\n",
        "> There is no general way to select a learning rate, but there are a couple of strategies. First, you try a very high learning rate (i.e. 0.1-0.5), expecting a model to fastly get into a local optima. Then you decrease the learning rate exponentially (from 0.1 to 0.01, 0.001, ...) and check the training speed by looking at the loss value decreasing with each epoch. What we want is to select such learning rate that the loss decreases during all epochs. We cannot do it precisely, but can have up to 5 runs to estimate a good learning rate.\n",
        "\n",
        "Another strategy is to use learning rate schedulers, the most popular is the exponential decay. We start with a high learning rate, then epoch by epoch (step by step) the learning rate decreases leading a model to a emperically good local optima.\n",
        "\n",
        "- Is image augmentation more effective with 32x32 or 224x224 size and why?\n",
        "\n",
        "> 224x224 models benefit more from image augmentaion because not only there are more variations of images that can be generated by augmentation algorithms, but also some of the algorithms can corrupt 32x32 images, for instance, rotating such small image by 10 degrees. So, only a small portion of image augmentation techniques are beneficial for 32x32 images.\n",
        "\n"
      ],
      "metadata": {
        "id": "VyoI54-cFJPo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "krJD5m-I5CXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}