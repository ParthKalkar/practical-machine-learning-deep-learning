{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gau9xEXMGY8s"
      },
      "source": [
        "# Neural Machine Translation with Attention Using PyTorch\n",
        "In this notebook we are going to perform machine translation using a deep learning based approach and attention mechanism. All the code is based on PyTorch and it was adopted from the tutorial provided on the official documentation of [TensorFlow](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb).\n",
        "\n",
        "Specifically, we are going to train a sequence to sequence model for French to English translation. \n",
        "\n",
        "Dataset is in moodle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z579-ISl9Zj6"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT20LFmb3jSW"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8Qy0eC0ZtA"
      },
      "source": [
        "f = open('Dataset-fr-eng.txt', encoding='UTF-8').read().strip().split('\\n')  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mVlB0W14b4G"
      },
      "source": [
        "lines = f\n",
        "# sample size (smaller sample size to reduce computation)\n",
        "num_examples = 30000 \n",
        "# creates lists containing each pair\n",
        "original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"fr\",\"whatever\"])\n",
        "data = data[['eng','fr']]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "913VSLih4lY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9772a932-0f40-4def-c560-639ff32d5dc1"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   eng       fr\n",
              "0  Go.     Va !\n",
              "1  Go.  Marche.\n",
              "2  Go.  Bouge !\n",
              "3  Hi.  Salut !\n",
              "4  Hi.   Salut."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a975f6b-7465-470c-ae99-55008df44e8b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a975f6b-7465-470c-ae99-55008df44e8b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a975f6b-7465-470c-ae99-55008df44e8b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a975f6b-7465-470c-ae99-55008df44e8b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCUSf31E4m6t"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    \"\"\"\n",
        "    Normalizes latin chars with accent to their canonical decomposition\n",
        "    \"\"\"\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2pLaZkNqrv"
      },
      "source": [
        "## Data Exploration\n",
        "Let's explore the dataset a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFLV4RCR4pXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b91f2e11-61a6-4adc-af60-3bc8106e9e70"
      },
      "source": [
        "# Now we do the preprocessing using pandas and lambdas\n",
        "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
        "data[\"fr\"] = data.fr.apply(lambda w: preprocess_sentence(w))\n",
        "data.sample(10)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      eng  \\\n",
              "29432       <start> i was born in . <end>   \n",
              "20170    <start> they re students . <end>   \n",
              "8678        <start> tom told mary . <end>   \n",
              "28004  <start> get away from here . <end>   \n",
              "21815    <start> you re very open . <end>   \n",
              "27329   <start> you re very smart . <end>   \n",
              "2306           <start> run for it ! <end>   \n",
              "22298   <start> does truth matter ? <end>   \n",
              "18595    <start> i was frustrated . <end>   \n",
              "13524     <start> i called him up . <end>   \n",
              "\n",
              "                                                      fr  \n",
              "29432  <start> je suis ne en mille neuf cent soixante...  \n",
              "20170             <start> ce sont des etudiantes . <end>  \n",
              "8678                 <start> tom l a dit a marie . <end>  \n",
              "28004                        <start> cassez vous . <end>  \n",
              "21815             <start> vous etes tres ouverts . <end>  \n",
              "27329             <start> tu es tres intelligent . <end>  \n",
              "2306         <start> prends tes jambes a ton cou ! <end>  \n",
              "22298           <start> la verite importe t elle ? <end>  \n",
              "18595                      <start> j etais agace . <end>  \n",
              "13524                <start> je lui ai telephone . <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-831ba1dd-2943-4882-8131-d63335cbb84f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29432</th>\n",
              "      <td>&lt;start&gt; i was born in . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; je suis ne en mille neuf cent soixante...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20170</th>\n",
              "      <td>&lt;start&gt; they re students . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ce sont des etudiantes . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8678</th>\n",
              "      <td>&lt;start&gt; tom told mary . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; tom l a dit a marie . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28004</th>\n",
              "      <td>&lt;start&gt; get away from here . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; cassez vous . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21815</th>\n",
              "      <td>&lt;start&gt; you re very open . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; vous etes tres ouverts . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27329</th>\n",
              "      <td>&lt;start&gt; you re very smart . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; tu es tres intelligent . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2306</th>\n",
              "      <td>&lt;start&gt; run for it ! &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; prends tes jambes a ton cou ! &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22298</th>\n",
              "      <td>&lt;start&gt; does truth matter ? &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; la verite importe t elle ? &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18595</th>\n",
              "      <td>&lt;start&gt; i was frustrated . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; j etais agace . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13524</th>\n",
              "      <td>&lt;start&gt; i called him up . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; je lui ai telephone . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-831ba1dd-2943-4882-8131-d63335cbb84f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-831ba1dd-2943-4882-8131-d63335cbb84f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-831ba1dd-2943-4882-8131-d63335cbb84f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqM7ZncM8V9B"
      },
      "source": [
        "#### Building Vocabulary Index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rXA7-N34sok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f648fb62-6748-4238-84fd-4631eb90d703"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word      \n",
        "\n",
        "\n",
        "# index language using the class above\n",
        "inp_lang = LanguageIndex(data[\"fr\"].values.tolist())\n",
        "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
        "# Vectorize the input and target languages\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"fr\"].values.tolist()]\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]\n",
        "input_tensor[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 7355, 1, 4],\n",
              " [5, 4357, 3, 4],\n",
              " [5, 905, 1, 4],\n",
              " [5, 6432, 1, 4],\n",
              " [5, 6432, 3, 4],\n",
              " [5, 1663, 1, 4],\n",
              " [5, 1655, 1, 4],\n",
              " [5, 5559, 7581, 3985, 7, 7581, 1677, 1, 4],\n",
              " [5, 3125, 1, 4],\n",
              " [5, 3127, 1, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fesymsn34v7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de82f35-267e-4372-c21b-c6005d75859a"
      },
      "source": [
        "target_tensor[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1588, 3, 4],\n",
              " [5, 1588, 3, 4],\n",
              " [5, 1588, 3, 4],\n",
              " [5, 1774, 3, 4],\n",
              " [5, 1774, 3, 4],\n",
              " [5, 3188, 1, 4],\n",
              " [5, 3188, 1, 4],\n",
              " [5, 3188, 1, 4],\n",
              " [5, 3188, 1, 4],\n",
              " [5, 3188, 1, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cwX-0rt4zmN"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "# calculate the max_length of input and output tensor\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "\n",
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66dJPqzV44jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2344691-2815-453f-bda9-ed50e8f2ce1c"
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
        "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
        "len(target_tensor)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvatfCWS46T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817f2940-8bbe-49b4-f552-e517f3f6d3be"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 24000, 6000, 6000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNFO3obpOsoB"
      },
      "source": [
        "## Load data into DataLoader for Batching\n",
        "This is just preparing the dataset so that it can be efficiently fed into the model through batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRQKwxf479Q"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDSxA4OM5Qlp"
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2WukeVF8NVn"
      },
      "source": [
        "## Parameters\n",
        "Let's define the hyperparameters and other things we need for training our NMT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Be7lOZ5R-d"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blYXo7pv5TOu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
        "        \n",
        "    def forward(self, x, lens, device):\n",
        "        # x: batch_size, max_length \n",
        "        \n",
        "        # x: batch_size, max_length, embedding_dim\n",
        "        x = self.embedding(x) \n",
        "                \n",
        "        # x transformed = max_len X batch_size X embedding_dim\n",
        "        # x = x.permute(1,0,2)\n",
        "        x = pack_padded_sequence(x, lens) # unpad\n",
        "    \n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        \n",
        "        # output: max_length, batch_size, enc_units\n",
        "        # self.hidden: 1, batch_size, enc_units\n",
        "        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
        "        \n",
        "        # pad the sequence to the max length in the batch\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        \n",
        "        return output, self.hidden\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "metadata": {
        "id": "6Z03l-LydpY-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Testing Encoder part\n",
        "# TODO: put whether GPU is available or not\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "\n",
        "print(enc_output.size()) # max_length, batch_size, enc_units"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSr07OV4dlGk",
        "outputId": "33863efa-7d5e-4ddb-b854-8cdcd289d9f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 64, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiMRxHQFGPtt"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Here, we'll implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input word is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
        "\n",
        "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*. \n",
        "\n",
        "Here are the equations that are implemented:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "We're using *Bahdanau attention*. Lets decide on notation before writing the simplified form:\n",
        "\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "\n",
        "And the pseudo-code:\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
        "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* This merged vector is then given to the GRU\n",
        "  \n",
        "The shapes of all the vectors at each step have been specified in the comments in the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4djvgil5bMQ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.V = nn.Linear(self.enc_units, 1)\n",
        "    \n",
        "    def forward(self, x, hidden, enc_output):\n",
        "        # enc_output original: (max_length, batch_size, enc_units)\n",
        "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        # It doesn't matter which FC we pick for each of the inputs\n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        \n",
        "        #score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n",
        "          \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        # takes case of the right portion of the model above (illustrated in red)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        # ? Looks like attention vector in diagram of source\n",
        "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        # output: (batch_size, 1, hidden_size)\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((1, self.batch_sz, self.dec_units))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QclyWIop5dRG"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
        "    loss_ = criterion(pred, real) * mask \n",
        "    return torch.mean(loss_)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjMMYJv85hVT"
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "print(\"Input: \", x.shape)\n",
        "print(\"Output: \", y.shape)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
        "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "#print(enc_hidden.squeeze(0).shape)\n",
        "\n",
        "dec_hidden = enc_hidden#.squeeze(0)\n",
        "dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "print(\"Decoder Input: \", dec_input.shape)\n",
        "print(\"--------\")\n",
        "\n",
        "for t in range(1, y.size(1)):\n",
        "    # enc_hidden: 1, batch_size, enc_units\n",
        "    # output: max_length, batch_size, enc_units\n",
        "    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "    \n",
        "    print(\"Prediction: \", predictions.shape)\n",
        "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
        "    \n",
        "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
        "    \n",
        "    dec_input = y[:, t].unsqueeze(1)\n",
        "    print(dec_input.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDqemrL5d2E5",
        "outputId": "9d1b3de6-119b-4248-f97e-d45f2d98b5fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  torch.Size([64, 17])\n",
            "Output:  torch.Size([64, 10])\n",
            "Encoder Output:  torch.Size([11, 64, 1024])\n",
            "Encoder Hidden:  torch.Size([1, 64, 1024])\n",
            "Decoder Input:  torch.Size([64, 1])\n",
            "--------\n",
            "Prediction:  torch.Size([64, 4356])\n",
            "Decoder Hidden:  torch.Size([1, 64, 1024])\n",
            "torch.Size([64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6_WoDZM7reU"
      },
      "source": [
        "## Training\n",
        "Now we start the training. We are only using 10 epochs but you can expand this to keep trainining the model for a longer period of time. Note that in this case we are teacher forcing during training. Find a more detailed explanation in the official TensorFlow [implementation](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb) of this notebook provided by the TensorFlow team. \n",
        "\n",
        "- Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
        "- The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
        "- The decoder returns the predictions and the decoder hidden state.\n",
        "- The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "- Use teacher forcing to decide the next input to the decoder.\n",
        "- Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "- The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpQU6MhEUfFL"
      },
      "source": [
        "def flip_batch(X, y):\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "ps-Agf3if2Ea"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8G-3YY8ADm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4a5108-3d59-48c6-d82b-fe75c568c8d9"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
        "        dec_hidden = enc_hidden\n",
        "        \n",
        "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "        \n",
        "        # run code below for every timestep in the ys batch\n",
        "        for t in range(1, ys.size(1)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
        "            #loss += loss_\n",
        "            dec_input = ys[:, t].unsqueeze(1)\n",
        "            \n",
        "        \n",
        "        batch_loss = (loss / int(ys.size(1)))\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.detach().item()))\n",
        "        \n",
        "        \n",
        "    ### TODO: Save checkpoint for model\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.8201\n",
            "Epoch 1 Batch 100 Loss 4.5460\n",
            "Epoch 1 Batch 200 Loss 4.6640\n",
            "Epoch 1 Batch 300 Loss 4.7332\n",
            "Epoch 1 Loss 4.6415\n",
            "Time taken for 1 epoch 17.48930597305298 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.7708\n",
            "Epoch 2 Batch 100 Loss 4.7041\n",
            "Epoch 2 Batch 200 Loss 4.7143\n",
            "Epoch 2 Batch 300 Loss 4.5863\n",
            "Epoch 2 Loss 4.6415\n",
            "Time taken for 1 epoch 16.880320072174072 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.5850\n",
            "Epoch 3 Batch 100 Loss 4.6751\n",
            "Epoch 3 Batch 200 Loss 4.6102\n",
            "Epoch 3 Batch 300 Loss 4.6680\n",
            "Epoch 3 Loss 4.6416\n",
            "Time taken for 1 epoch 17.5241801738739 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 4.5224\n",
            "Epoch 4 Batch 100 Loss 4.7295\n",
            "Epoch 4 Batch 200 Loss 4.7702\n",
            "Epoch 4 Batch 300 Loss 4.7192\n",
            "Epoch 4 Loss 4.6415\n",
            "Time taken for 1 epoch 16.63280701637268 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 4.4781\n",
            "Epoch 5 Batch 100 Loss 4.6536\n",
            "Epoch 5 Batch 200 Loss 4.6795\n",
            "Epoch 5 Batch 300 Loss 4.5460\n",
            "Epoch 5 Loss 4.6415\n",
            "Time taken for 1 epoch 16.737494230270386 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 4.6374\n",
            "Epoch 6 Batch 100 Loss 4.6684\n",
            "Epoch 6 Batch 200 Loss 4.6772\n",
            "Epoch 6 Batch 300 Loss 4.7186\n",
            "Epoch 6 Loss 4.6415\n",
            "Time taken for 1 epoch 16.73861002922058 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 4.5973\n",
            "Epoch 7 Batch 100 Loss 4.7985\n",
            "Epoch 7 Batch 200 Loss 4.6002\n",
            "Epoch 7 Batch 300 Loss 4.7197\n",
            "Epoch 7 Loss 4.6415\n",
            "Time taken for 1 epoch 16.73156762123108 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 4.6938\n",
            "Epoch 8 Batch 100 Loss 4.6911\n",
            "Epoch 8 Batch 200 Loss 4.7158\n",
            "Epoch 8 Batch 300 Loss 4.6749\n",
            "Epoch 8 Loss 4.6415\n",
            "Time taken for 1 epoch 16.705761671066284 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 4.7456\n",
            "Epoch 9 Batch 100 Loss 4.7814\n",
            "Epoch 9 Batch 200 Loss 4.6516\n",
            "Epoch 9 Batch 300 Loss 4.5060\n",
            "Epoch 9 Loss 4.6416\n",
            "Time taken for 1 epoch 16.687217950820923 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 4.6892\n",
            "Epoch 10 Batch 100 Loss 4.6519\n",
            "Epoch 10 Batch 200 Loss 4.5603\n",
            "Epoch 10 Batch 300 Loss 4.4965\n",
            "Epoch 10 Loss 4.6415\n",
            "Time taken for 1 epoch 16.7390775680542 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "metadata": {
        "id": "TEXCpo1chPSC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYBffn-2Hao"
      },
      "source": [
        "# def translate_sentence(encoder, decoder, sentence, max_length=120):\n",
        "#     encoder.eval()\n",
        "#     decoder.eval()\n",
        "#     total_loss = 0\n",
        "#     sentence = torch.unsqueeze(sentence, dim=1)\n",
        "#     with torch.no_grad():\n",
        "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#         enc_output, enc_hidden = encoder(sentence.to(device), device)\n",
        "#         dec_hidden = enc_hidden\n",
        "#         dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * 1)\n",
        "#         out_sentence = []\n",
        "#         for t in range(1, sentence.size(0)):\n",
        "#             predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "#                                         dec_hidden.to(device), \n",
        "#                                         enc_output.to(device))\n",
        "#             dec_input = predictions.argmax(dim=1).unsqueeze(1)\n",
        "#             out_sentence.append(targ_lang.idx2word[predictions.squeeze().argmax().item()])\n",
        "\n",
        "#     return out_sentence\n",
        "\n",
        "# encoder.batch_sz = 1\n",
        "# encoder.initialize_hidden_state(device)\n",
        "# decoder.batch_sz = 1\n",
        "# decoder.initialize_hidden_state()\n",
        "\n",
        "# test_sentence = \"<start> j adore les fleurs . <end>\"\n",
        "# test_sentence = [inp_lang.word2idx[s] for s in test_sentence.split(' ')]\n",
        "# test_sentence = pad_sequences(test_sentence, max_length_inp)\n",
        "# ret = translate_sentence(encoder, decoder, torch.tensor(test_sentence), max_length=120)\n",
        "# ret"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAcd2vJINHj1"
      },
      "source": [
        "### References\n",
        "\n",
        "\n",
        "\n",
        "1.   http://www.adeveloperdiary.com/data-science/deep-learning/nlp/machine-translation-using-attention-with-pytorch/\n",
        "2.   https://medium.com/dair-ai/neural-machine-translation-with-attention-using-pytorch-a66523f1669f\n",
        "\n",
        "\n"
      ]
    }
  ]
}