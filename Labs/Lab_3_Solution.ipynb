{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 3 on Practical Machine Learning and Deep Learning\n",
        "\n",
        "Author: Danis Alukaev <br>\n",
        "Group: B19-DS-01 <br>\n",
        "Email: d.alukaev@innopolis.university"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQlyqnDLDNw"
      },
      "source": [
        "# German traffic sign recognition \n",
        "\n",
        "Imagine you are working in self-driving project as a machine learning engineer. One of the important problems for self-driving cars is to follow traffic signs. A car moves and collects video from the front camera. In each separate image you could localize the signs and after that understand what sign did we find.\n",
        "\n",
        "We can assume that someone else is responsible for localizing and tracking signs, and your task is to do the classification part.\n",
        "\n",
        "In today's lab you will be asked to develop a traffic sign recognition system. It should take a sign image and classify which of 43 signs it belongs to.\n",
        "\n",
        "In this problem you will be given a benchmark dataset The German Traffic Sign Recognition Benchmark: A multi-class classification competition.\n",
        "\n",
        "Overview\n",
        "1. multi-class classification problem\n",
        "2. More than 40 classes\n",
        "3. More than 50,000 images in total\n",
        "4. Large, lifelike database\n",
        "5. Reliable ground-truth data due to semi-automatic annotation\n",
        "Physical traffic sign instances are unique within the dataset\n",
        "(i.e., each real-world traffic sign only occurs once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jhEn17aRa4dO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/danis/anaconda3/envs/bottleneck/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import os \n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have downloaded dataset from [Kaggle Competition](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) and trained model locally on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "### GET THE DATA FROM DRIVE\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !unzip 'drive/MyDrive/GTSRB/GTRSB.zip'\n",
        "\n",
        "!unzip 'GTSRB.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I put these hyperparameters in separate cell and increased image size to 299."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 70\n",
        "IMAGE_SIZE = 299\n",
        "EPOCHS = 10\n",
        "NB_CLASS = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fetujjC0buC3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data 39209  Test data 12630 \n"
          ]
        }
      ],
      "source": [
        "### The dataset contains Train and Test folders + Train.csv and Test.csv\n",
        "### TASK : load data using csv file \n",
        "\n",
        "def get_data(csv_data):\n",
        "    images, labels = [], []\n",
        "    ### open csv file\n",
        "    df = pd.read_csv(csv_data)\n",
        "\n",
        "    ### iterate the csv , for each row get image from the 'Path' column and get label from the column 'ClassId'\n",
        "    for idx, row in df.iterrows():\n",
        "        images.append(np.array(Image.open(row['Path'])))\n",
        "        labels.append(row['ClassId'])\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "### Next we need to build a custom Dataset in Pytorch, this dataset will be given after that to the Dataloader \n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transforms=None):\n",
        "        self.labels = labels\n",
        "        self.images = images \n",
        "        self.transform = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    ### Define augmentations \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "    ### Don't forget to convert to tensor\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "   ### put code here\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "])\n",
        "\n",
        "x_train, y_train = get_data('Train.csv')\n",
        "train_data = CustomDataset(x_train, y_train, transforms=train_transform)\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "x_test, y_test = get_data('Test.csv')\n",
        "test_data = CustomDataset(x_test, y_test, transforms=test_transform)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print(\"Train data %.d  Test data %.d \"%(len(train_loader.dataset),len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following cell I have implemented simple CNN and used InceptionV3 for fine-tuning. Note that there are pairs of optimizers and schedulers compared to original notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WSykQLtobOkv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "### If you run on GPU you must load it to device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "### TASK : Define 2 models the first a simple CNN and the second choose any pretrained model\n",
        "\n",
        "class CNN_model(nn.Module):\n",
        "\n",
        "    def __init__(self, nb_class):\n",
        "        super(CNN_model, self).__init__()\n",
        "        ### define layers here\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3))\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128) \n",
        "\n",
        "        self.fc1 = nn.Linear(156800, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 128)\n",
        "        self.fc3 = nn.Linear(128, nb_class)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.pool(F.relu(self.conv1(x))))\n",
        "        x = self.bn2(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.bn3(self.pool(F.relu(self.conv3(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "class Pretrained_model(nn.Module):\n",
        "    \n",
        "    def __init__(self, nb_class):\n",
        "        super(Pretrained_model, self).__init__()\n",
        "\n",
        "        ### from torchvision.models choose a pretrained model\n",
        "        # I selected InceptionV3 as pretrained model.\n",
        "\n",
        "        model = torchvision.models.inception_v3(pretrained=True)\n",
        "        model.AuxLogits.fc = nn.Linear(768, nb_class)\n",
        "        model.fc = nn.Linear(2048, nb_class)\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        if self.training:\n",
        "            x, _ = x\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN_model(NB_CLASS).to(device)\n",
        "model_ft = Pretrained_model(NB_CLASS).to(device)\n",
        "\n",
        "# Loss function here\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# Optimizer here\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "# Scheduler here\n",
        "schedule = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "schedule_ft = optim.lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Iv7S9b4LbxZn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def count_correct(y_pred, y):\n",
        "    ### task : make a function that counts correctly classified samples\n",
        "    _, predicted_classes = y_pred.max(1)\n",
        "    predicted_classes = predicted_classes.cpu().detach().numpy()\n",
        "    y = y.cpu().detach().numpy()\n",
        "    acc = (y == predicted_classes).sum()\n",
        "    return acc\n",
        "\n",
        "def train(model, train_loader, loss_fn, optimizer,scheduler,device):\n",
        "    epoch_accuracy = 0\n",
        "    epoch_correct = 0\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # task : get the images and labels and don't forget to load to device (2 lines)\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients, it's a must \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # task : get the loss \n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()* images.size(0)\n",
        "        total += images.size(0)\n",
        "        correct += count_correct(outputs, labels)\n",
        "        epoch_accuracy = correct / total\n",
        "        \n",
        "        # task : print statistics here (once in 100 iterations)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: loss={running_loss / total:.3f} acc={epoch_accuracy:.3f}\")\n",
        "\n",
        "        \n",
        "def evaluate(model, loader, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in loader:\n",
        "            ## task :get images and labels and add to device \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            output = model(images)\n",
        "            epoch_loss += criterion(output, labels)\n",
        "            \n",
        "            total += labels.shape[0]\n",
        "\n",
        "            # Count correctly classified samples\n",
        "            correct += count_correct(output, labels)\n",
        "            \n",
        "            ### task : print statistics\n",
        "        print(f\"Validation: loss={epoch_loss / total:.3f} acc={correct / total:.3f}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Test the designed CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "Iteration 0: loss=3.761 acc=0.043\n",
            "Iteration 100: loss=3.778 acc=0.229\n",
            "Iteration 200: loss=2.963 acc=0.336\n",
            "Iteration 300: loss=2.475 acc=0.418\n",
            "Iteration 400: loss=2.096 acc=0.494\n",
            "Iteration 500: loss=1.823 acc=0.555\n",
            "Validation: loss=0.019 acc=0.692\n",
            "Epoch #2\n",
            "Iteration 0: loss=0.797 acc=0.786\n",
            "Iteration 100: loss=0.555 acc=0.862\n",
            "Iteration 200: loss=0.479 acc=0.881\n",
            "Iteration 300: loss=0.430 acc=0.895\n",
            "Iteration 400: loss=0.408 acc=0.900\n",
            "Iteration 500: loss=0.389 acc=0.904\n",
            "Validation: loss=0.015 acc=0.799\n",
            "Epoch #3\n",
            "Iteration 0: loss=0.167 acc=0.957\n",
            "Iteration 100: loss=0.246 acc=0.940\n",
            "Iteration 200: loss=0.204 acc=0.949\n",
            "Iteration 300: loss=0.185 acc=0.953\n",
            "Iteration 400: loss=0.183 acc=0.954\n",
            "Iteration 500: loss=0.183 acc=0.953\n",
            "Validation: loss=0.011 acc=0.811\n",
            "Epoch #4\n",
            "Iteration 0: loss=0.057 acc=0.986\n",
            "Iteration 100: loss=0.094 acc=0.976\n",
            "Iteration 200: loss=0.112 acc=0.973\n",
            "Iteration 300: loss=0.150 acc=0.965\n",
            "Iteration 400: loss=0.138 acc=0.967\n",
            "Iteration 500: loss=0.131 acc=0.968\n",
            "Validation: loss=0.011 acc=0.878\n",
            "Epoch #5\n",
            "Iteration 0: loss=0.123 acc=0.971\n",
            "Iteration 100: loss=0.125 acc=0.968\n",
            "Iteration 200: loss=0.127 acc=0.968\n",
            "Iteration 300: loss=0.126 acc=0.969\n",
            "Iteration 400: loss=0.114 acc=0.973\n",
            "Iteration 500: loss=0.111 acc=0.974\n",
            "Validation: loss=0.008 acc=0.903\n",
            "Epoch #6\n",
            "Iteration 0: loss=0.035 acc=0.986\n",
            "Iteration 100: loss=0.089 acc=0.982\n",
            "Iteration 200: loss=0.089 acc=0.980\n",
            "Iteration 300: loss=0.087 acc=0.980\n",
            "Iteration 400: loss=0.081 acc=0.982\n",
            "Iteration 500: loss=0.080 acc=0.982\n",
            "Validation: loss=0.012 acc=0.867\n",
            "Epoch #7\n",
            "Iteration 0: loss=0.159 acc=0.971\n",
            "Iteration 100: loss=0.108 acc=0.978\n",
            "Iteration 200: loss=0.083 acc=0.982\n",
            "Iteration 300: loss=0.089 acc=0.980\n",
            "Iteration 400: loss=0.090 acc=0.980\n",
            "Iteration 500: loss=0.093 acc=0.979\n",
            "Validation: loss=0.010 acc=0.899\n",
            "Epoch #8\n",
            "Iteration 0: loss=0.014 acc=1.000\n",
            "Iteration 100: loss=0.083 acc=0.985\n",
            "Iteration 200: loss=0.077 acc=0.985\n",
            "Iteration 300: loss=0.065 acc=0.987\n",
            "Iteration 400: loss=0.058 acc=0.988\n",
            "Iteration 500: loss=0.059 acc=0.988\n",
            "Validation: loss=0.012 acc=0.862\n",
            "Epoch #9\n",
            "Iteration 0: loss=0.000 acc=1.000\n",
            "Iteration 100: loss=0.055 acc=0.988\n",
            "Iteration 200: loss=0.048 acc=0.989\n",
            "Iteration 300: loss=0.039 acc=0.991\n",
            "Iteration 400: loss=0.040 acc=0.991\n",
            "Iteration 500: loss=0.046 acc=0.990\n",
            "Validation: loss=0.015 acc=0.851\n",
            "Epoch #10\n",
            "Iteration 0: loss=0.126 acc=0.971\n",
            "Iteration 100: loss=0.094 acc=0.983\n",
            "Iteration 200: loss=0.105 acc=0.981\n",
            "Iteration 300: loss=0.095 acc=0.982\n",
            "Iteration 400: loss=0.082 acc=0.984\n",
            "Iteration 500: loss=0.075 acc=0.986\n",
            "Validation: loss=0.017 acc=0.852\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch #{epoch + 1}\")\n",
        "    train(model, train_loader, loss_fn, optimizer, schedule, device)\n",
        "    evaluate(model, test_loader, loss_fn, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom model achieved `85.2%`. Not bad at all! Let's see how fine-tuned model will perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine-tune and Test InceptionV3 (for bonus point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h9mwO7dcbyT3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "Iteration 0: loss=3.802 acc=0.043\n",
            "Iteration 100: loss=0.722 acc=0.809\n",
            "Iteration 200: loss=0.428 acc=0.889\n",
            "Iteration 300: loss=0.315 acc=0.918\n",
            "Iteration 400: loss=0.251 acc=0.935\n",
            "Iteration 500: loss=0.212 acc=0.945\n",
            "Validation: loss=0.001 acc=0.978\n",
            "Epoch #2\n",
            "Iteration 0: loss=0.032 acc=0.986\n",
            "Iteration 100: loss=0.068 acc=0.982\n",
            "Iteration 200: loss=0.063 acc=0.983\n",
            "Iteration 300: loss=0.051 acc=0.987\n",
            "Iteration 400: loss=0.043 acc=0.989\n",
            "Iteration 500: loss=0.038 acc=0.990\n",
            "Validation: loss=0.002 acc=0.967\n",
            "Epoch #3\n",
            "Iteration 0: loss=0.032 acc=0.986\n",
            "Iteration 100: loss=0.014 acc=0.997\n",
            "Iteration 200: loss=0.020 acc=0.995\n",
            "Iteration 300: loss=0.030 acc=0.993\n",
            "Iteration 400: loss=0.028 acc=0.994\n",
            "Iteration 500: loss=0.027 acc=0.994\n",
            "Validation: loss=0.002 acc=0.971\n",
            "Epoch #4\n",
            "Iteration 0: loss=0.013 acc=1.000\n",
            "Iteration 100: loss=0.057 acc=0.987\n",
            "Iteration 200: loss=0.034 acc=0.992\n",
            "Iteration 300: loss=0.026 acc=0.994\n",
            "Iteration 400: loss=0.026 acc=0.993\n",
            "Iteration 500: loss=0.027 acc=0.993\n",
            "Validation: loss=0.001 acc=0.976\n",
            "Epoch #5\n",
            "Iteration 0: loss=0.073 acc=0.986\n",
            "Iteration 100: loss=0.016 acc=0.996\n",
            "Iteration 200: loss=0.015 acc=0.996\n",
            "Iteration 300: loss=0.013 acc=0.997\n",
            "Iteration 400: loss=0.013 acc=0.997\n",
            "Iteration 500: loss=0.012 acc=0.997\n",
            "Validation: loss=0.001 acc=0.986\n",
            "Epoch #6\n",
            "Iteration 0: loss=0.000 acc=1.000\n",
            "Iteration 100: loss=0.003 acc=0.999\n",
            "Iteration 200: loss=0.005 acc=0.998\n",
            "Iteration 300: loss=0.009 acc=0.997\n",
            "Iteration 400: loss=0.009 acc=0.998\n",
            "Iteration 500: loss=0.009 acc=0.998\n",
            "Validation: loss=0.002 acc=0.974\n",
            "Epoch #7\n",
            "Iteration 0: loss=0.053 acc=0.986\n",
            "Iteration 100: loss=0.018 acc=0.996\n",
            "Iteration 200: loss=0.016 acc=0.996\n",
            "Iteration 300: loss=0.016 acc=0.997\n",
            "Iteration 400: loss=0.023 acc=0.995\n",
            "Iteration 500: loss=0.034 acc=0.993\n",
            "Validation: loss=0.001 acc=0.977\n",
            "Epoch #8\n",
            "Iteration 0: loss=0.063 acc=0.971\n",
            "Iteration 100: loss=0.010 acc=0.996\n",
            "Iteration 200: loss=0.011 acc=0.997\n",
            "Iteration 300: loss=0.010 acc=0.998\n",
            "Iteration 400: loss=0.009 acc=0.998\n",
            "Iteration 500: loss=0.009 acc=0.998\n",
            "Validation: loss=0.001 acc=0.984\n",
            "Epoch #9\n",
            "Iteration 0: loss=0.005 acc=1.000\n",
            "Iteration 100: loss=0.030 acc=0.993\n",
            "Iteration 200: loss=0.018 acc=0.996\n",
            "Iteration 300: loss=0.013 acc=0.997\n",
            "Iteration 400: loss=0.011 acc=0.997\n",
            "Iteration 500: loss=0.010 acc=0.997\n",
            "Validation: loss=0.001 acc=0.987\n",
            "Epoch #10\n",
            "Iteration 0: loss=0.000 acc=1.000\n",
            "Iteration 100: loss=0.004 acc=0.999\n",
            "Iteration 200: loss=0.007 acc=0.998\n",
            "Iteration 300: loss=0.007 acc=0.998\n",
            "Iteration 400: loss=0.007 acc=0.998\n",
            "Iteration 500: loss=0.008 acc=0.998\n",
            "Validation: loss=0.001 acc=0.983\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch #{epoch + 1}\")\n",
        "    train(model_ft, train_loader, loss_fn, optimizer_ft, schedule_ft, device)\n",
        "    evaluate(model_ft, test_loader, loss_fn, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wow, we achieved an accuracy of `98.3%` on test set, that's cool!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab4 - GTSRB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
