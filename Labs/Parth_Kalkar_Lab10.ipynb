{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7Wqg9HiBl5-Y",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Graph Convolutional Network\n",
        "#### List of GNN Applications:\n",
        "\n",
        "* Node classification: The objective here is to predict the labels of nodes by considering the labels of their neighbors. \n",
        "* Link prediction: In this case, the goal is to predict the relationship between various entities in a graph. This can for example be applied in prediction connections for social networks. \n",
        "* Graph clustering: This involves dividing the nodes of a graph into clusters. The partitioning can be done based on edge weights or edge distances or by considering the graphs as objects and grouping similar objects together. \n",
        "* Graph classification: This entails classifying a graph into a category. This can be applied in social network analysis and categorizing documents in natural language processing. Other applications in NLP include text classification, extracting semantic relationships between texts, and sequence labeling. \n",
        "* Computer vision: In the computer vision world, GNNs can be used to generate regions of interest for object detection. They can also be used in image classification whereby a scene graph is generated. The scene generation model then identifies objects in the image and the semantic relationship between them. Other applications in this field include interaction detection and region classification. \n",
        "\n",
        "#### GCN implementation with DGL\n",
        "\n",
        "One of the most popular and widely adopted tasks on graph data is node classification, where a model needs to predict the ground truth category of each node. Before graph neural networks, many proposed methods are using either connectivity alone (such as DeepWalk or node2vec), or simple combinations of connectivity and the node’s own features. GNNs, by contrast, offers an opportunity to obtain node representations by combining the connectivity and features of a local neighborhood."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node classification"
      ],
      "metadata": {
        "id": "WcA6Ib65Pc-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "JNqVUBJ4-3KF",
        "outputId": "77c3ef24-0d49-484e-e655-0b474c25cea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.7.3)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Installing collected packages: psutil, dgl\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-0.9.1 psutil-5.9.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cz-0xIqml5-i",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed65f4bb-8171-4eb1-afcd-b42717567ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "from dgl import DGLGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLXTJm7ql5-n",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The forward function is essentially the same as any other commonly seen NNs model in PyTorch. We can initialize GCN like any nn.Module. For example, let’s define a simple neural network consisting of two GCN layers. Suppose we are training the classifier for the cora dataset (the input feature size is 1433 and the number of classes is 7). The last GCN layer computes node embeddings, so the last layer in general does not apply activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g7OYrB88l5-o",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in6r7GePl5-p",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We load the cora dataset using DGL’s built-in data module.\n",
        "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZZG5EDkJl5-r",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from dgl.data import CoraGraphDataset\n",
        "\n",
        "def load_cora_data():\n",
        "    dataset = CoraGraphDataset()\n",
        "    g = dataset[0]\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    return g, features, labels, train_mask, test_mask, dataset.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NdKHo_fCUne",
        "outputId": "84dfcf0e-d325-4bbf-ccff-3d856fae5f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n",
            "Node features\n",
            "{'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
            "Edge features\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "g, features, labels, train_mask, test_mask, num_classes = load_cora_data()\n",
        "print('Node features')\n",
        "print(g.ndata)\n",
        "print('Edge features')\n",
        "print(g.edata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ73_qRul5-t",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "When a model is trained, we can use the following method to evaluate the performance of the model on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zSzR_NWZl5-u",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(model, g, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(g, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WhtcFxRl5-v",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Task: Complete the training process and run and check the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "slENanvPl5-w",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f505d313-68ae-491c-e5bc-d0d86b7b78b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00000 | Loss 1.9462 | Test Acc 0.1560\n",
            "Epoch 00001 | Loss 1.9380 | Test Acc 0.3830\n",
            "Epoch 00002 | Loss 1.9288 | Test Acc 0.6010\n",
            "Epoch 00003 | Loss 1.9169 | Test Acc 0.6300\n",
            "Epoch 00004 | Loss 1.9031 | Test Acc 0.5410\n",
            "Epoch 00005 | Loss 1.8881 | Test Acc 0.4740\n",
            "Epoch 00006 | Loss 1.8728 | Test Acc 0.4710\n",
            "Epoch 00007 | Loss 1.8566 | Test Acc 0.4850\n",
            "Epoch 00008 | Loss 1.8387 | Test Acc 0.4940\n",
            "Epoch 00009 | Loss 1.8194 | Test Acc 0.4930\n",
            "Epoch 00010 | Loss 1.7998 | Test Acc 0.5000\n",
            "Epoch 00011 | Loss 1.7790 | Test Acc 0.5210\n",
            "Epoch 00012 | Loss 1.7568 | Test Acc 0.5440\n",
            "Epoch 00013 | Loss 1.7328 | Test Acc 0.5540\n",
            "Epoch 00014 | Loss 1.7075 | Test Acc 0.5590\n",
            "Epoch 00015 | Loss 1.6817 | Test Acc 0.5690\n",
            "Epoch 00016 | Loss 1.6552 | Test Acc 0.5890\n",
            "Epoch 00017 | Loss 1.6277 | Test Acc 0.6030\n",
            "Epoch 00018 | Loss 1.5991 | Test Acc 0.6150\n",
            "Epoch 00019 | Loss 1.5696 | Test Acc 0.6250\n",
            "Epoch 00020 | Loss 1.5392 | Test Acc 0.6350\n",
            "Epoch 00021 | Loss 1.5081 | Test Acc 0.6490\n",
            "Epoch 00022 | Loss 1.4761 | Test Acc 0.6560\n",
            "Epoch 00023 | Loss 1.4433 | Test Acc 0.6640\n",
            "Epoch 00024 | Loss 1.4098 | Test Acc 0.6690\n",
            "Epoch 00025 | Loss 1.3758 | Test Acc 0.6690\n",
            "Epoch 00026 | Loss 1.3412 | Test Acc 0.6680\n",
            "Epoch 00027 | Loss 1.3062 | Test Acc 0.6670\n",
            "Epoch 00028 | Loss 1.2709 | Test Acc 0.6720\n",
            "Epoch 00029 | Loss 1.2354 | Test Acc 0.6740\n",
            "Epoch 00030 | Loss 1.1996 | Test Acc 0.6810\n",
            "Epoch 00031 | Loss 1.1636 | Test Acc 0.6880\n",
            "Epoch 00032 | Loss 1.1275 | Test Acc 0.6960\n",
            "Epoch 00033 | Loss 1.0914 | Test Acc 0.6990\n",
            "Epoch 00034 | Loss 1.0553 | Test Acc 0.7080\n",
            "Epoch 00035 | Loss 1.0195 | Test Acc 0.7140\n",
            "Epoch 00036 | Loss 0.9839 | Test Acc 0.7190\n",
            "Epoch 00037 | Loss 0.9486 | Test Acc 0.7260\n",
            "Epoch 00038 | Loss 0.9137 | Test Acc 0.7290\n",
            "Epoch 00039 | Loss 0.8792 | Test Acc 0.7330\n",
            "Epoch 00040 | Loss 0.8453 | Test Acc 0.7420\n",
            "Epoch 00041 | Loss 0.8120 | Test Acc 0.7450\n",
            "Epoch 00042 | Loss 0.7793 | Test Acc 0.7470\n",
            "Epoch 00043 | Loss 0.7473 | Test Acc 0.7490\n",
            "Epoch 00044 | Loss 0.7161 | Test Acc 0.7490\n",
            "Epoch 00045 | Loss 0.6857 | Test Acc 0.7500\n",
            "Epoch 00046 | Loss 0.6561 | Test Acc 0.7500\n",
            "Epoch 00047 | Loss 0.6274 | Test Acc 0.7570\n",
            "Epoch 00048 | Loss 0.5996 | Test Acc 0.7600\n",
            "Epoch 00049 | Loss 0.5727 | Test Acc 0.7600\n"
          ]
        }
      ],
      "source": [
        "# Create the model with given dimensions\n",
        "model = GCN(g.ndata['feat'].shape[1], 16, num_classes)\n",
        "# Add edges between each node and itself to preserve old node representations\n",
        "g.add_edges(g.nodes(), g.nodes())\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "for epoch in range(50):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Write 3 lines of code to call the network on the graph\n",
        "    logits = model(g, features)\n",
        "    # Apply log_softmax on the logits\n",
        "    logits = F.log_softmax(logits)\n",
        "    # Apply NLL_loss on the scores while applying train_mask\n",
        "    loss = F.nll_loss(logits[train_mask], labels[train_mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = evaluate(model, g, features, labels, test_mask)\n",
        "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f}\".format(\n",
        "            epoch, loss.item(), acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link prediction\n",
        "Many applications such as social recommendation, item recommendation, knowledge graph completion, etc., can be formulated as link prediction, which predicts whether an edge exists between two particular nodes. This tutorial shows an example of predicting whether a citation relationship, either citing or being cited, between two papers exists in a citation network."
      ],
      "metadata": {
        "id": "f3PUCS5uPbH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "541Uovu0PjZI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare training and testing sets"
      ],
      "metadata": {
        "id": "2s_gLW9AQGRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g, features, labels, train_mask, test_mask, num_classes = load_cora_data()\n",
        "\n",
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMtSZz3PyLp",
        "outputId": "5929d806-4d32-43eb-bb2c-e38d0c134497"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "hC4AQHO2Rqox"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build a model consisting of two GraphSAGE layers, each computes new node representations by averaging neighbor information. DGL provides dgl.nn.SAGEConv that conveniently creates a GraphSAGE layer."
      ],
      "metadata": {
        "id": "ebnt3K9LQYT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "AvNkcENfQXul"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model then predicts the probability of existence of an edge by computing a score between the representations of both incident nodes with a function (e.g. an MLP or a dot product).\n",
        "\n",
        "DGL recommends you to treat the pairs of nodes as another graph, since you can describe a pair of nodes with an edge. In link prediction, you will have a positive graph consisting of all the positive examples as edges, and a negative graph consisting of all the negative examples. The positive graph and the negative graph will contain the same set of nodes as the original graph. This makes it easier to pass node features among multiple graphs for computation. As you will see later, you can directly feed the node representations computed on the entire graph to the positive and the negative graphs for computing pair-wise scores.\n",
        "\n",
        "The following code constructs the positive graph and the negative graph for the training set and the test set respectively."
      ],
      "metadata": {
        "id": "25EVBlXuQhft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "metadata": {
        "id": "gXLuCE2cQqLQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The benefit of treating the pairs of nodes as a graph is that you can use the DGLGraph.apply_edges method, which conveniently computes new edge features based on the incident nodes’ features and the original edge features (if applicable).\n",
        "\n",
        "DGL provides a set of optimized builtin functions to compute new edge features based on the original node/edge features. For example, dgl.function.u_dot_v computes a dot product of the incident nodes’ representations for each edge."
      ],
      "metadata": {
        "id": "b3cWH0ZDRA6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]"
      ],
      "metadata": {
        "id": "INPZB2qjQt8I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also write your own function if it is complex. For instance, the following module produces a scalar score on each edge by concatenating the incident nodes’ features and passing it to an MLP."
      ],
      "metadata": {
        "id": "rOn3CeRFSAqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']"
      ],
      "metadata": {
        "id": "E0ck2jJ1QxM5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "\n",
        "# You can replace DotPredictor with MLPPredictor.\n",
        "# pred = MLPPredictor(16)\n",
        "\n",
        "pred = DotPredictor()\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    # define labels, 1 line\n",
        "    labels = torch.cat((torch.ones(pos_score.shape), torch.zeros(neg_score.shape)))\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    # define labels, 1 line\n",
        "    labels = torch.cat((torch.ones(pos_score.shape), torch.zeros(neg_score.shape)))\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "XXhPLUSLQzF9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata['feat'])\n",
        "\n",
        "    # predict train pos and train neg scores, and compute loss, 3 lines\n",
        "    train_pos_pred = pred(train_pos_g, h)\n",
        "    train_neg_pred = pred(train_neg_g, h)\n",
        "    loss = compute_loss(train_pos_pred, train_neg_pred)\n",
        "    \n",
        "    # loss = compute_loss()\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zK-4vDjRghS",
        "outputId": "27ca72fb-92f2-4188-92dd-0091a8098f36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.6929841041564941\n",
            "In epoch 5, loss: 0.6652697920799255\n",
            "In epoch 10, loss: 0.576982855796814\n",
            "In epoch 15, loss: 0.5071618556976318\n",
            "In epoch 20, loss: 0.4702264666557312\n",
            "In epoch 25, loss: 0.4362088739871979\n",
            "In epoch 30, loss: 0.41358429193496704\n",
            "In epoch 35, loss: 0.38888028264045715\n",
            "In epoch 40, loss: 0.3662951588630676\n",
            "In epoch 45, loss: 0.3438146114349365\n",
            "In epoch 50, loss: 0.3205651044845581\n",
            "In epoch 55, loss: 0.29764366149902344\n",
            "In epoch 60, loss: 0.274132639169693\n",
            "In epoch 65, loss: 0.25071215629577637\n",
            "In epoch 70, loss: 0.2272685319185257\n",
            "In epoch 75, loss: 0.2039857655763626\n",
            "In epoch 80, loss: 0.18112502992153168\n",
            "In epoch 85, loss: 0.15937282145023346\n",
            "In epoch 90, loss: 0.13829749822616577\n",
            "In epoch 95, loss: 0.11842048913240433\n",
            "AUC 0.8489899148716336\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}